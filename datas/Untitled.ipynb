{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b97a80aa-8440-4169-9f4b-0d9d45db3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model\n",
    "import os\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35be3c65-f322-4af4-97ee-c76c599f16ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing: soilmoisture.csv\n",
      "Successfully extracted 2 high drought temperature rows.\n",
      "Loading RGB data from: 30to40.csv\n",
      "Successfully loaded 10000 RGB rows.\n",
      "Data combination complete. Final dataset size: 10000 rows.\n",
      "\n",
      "--- SUCCESS ---\n",
      "Clean, combined data saved to: combined_rgb_temp_data.csv\n",
      "Final columns: ['R', 'G', 'B', 'Drought_AmbientTemp', 'Drought_ObjectTemp']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "\n",
    "# --- 1. Function to Extract and Clean 'High Drought' Data from soilmoisture.csv ---\n",
    "def extract_high_drought_data(filepath):\n",
    "    \"\"\"\n",
    "    Parses the messy soilmoisture.csv file and extracts only the data \n",
    "    associated with the '# high drougt' section, keeping ONLY the Ambient Temp \n",
    "    and Object Temp (the second and third columns). The Soil Moisture column is dropped.\n",
    "    \"\"\"\n",
    "    print(f\"Parsing: {filepath}\")\n",
    "    \n",
    "    start_marker = \"# high drougt\"\n",
    "    end_marker = \"# medium high dought\" \n",
    "    \n",
    "    data_lines = []\n",
    "    is_in_section = False\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                \n",
    "                if line.startswith(start_marker):\n",
    "                    is_in_section = True\n",
    "                    continue\n",
    "                \n",
    "                if is_in_section and line.startswith(end_marker):\n",
    "                    break\n",
    "                \n",
    "                if is_in_section:\n",
    "                    # Ignore comment lines and non-numeric lines\n",
    "                    if line and not line.startswith('#') and not any(char.isalpha() for char in line):\n",
    "                        try:\n",
    "                            # Split by comma. Expected structure: Soil Moisture, Ambient Temp, Object Temp.\n",
    "                            parts = [float(p.strip()) for p in line.split(',')]\n",
    "                            if len(parts) == 3:\n",
    "                                # KEEP Ambient Temp (parts[1]) and Object Temp (parts[2])\n",
    "                                data_lines.append([parts[1], parts[2]]) \n",
    "                        except ValueError:\n",
    "                            continue\n",
    "\n",
    "        if not data_lines:\n",
    "            raise ValueError(\"No valid data found in the 'high drougt' section.\")\n",
    "            \n",
    "        # Create DataFrame with only the desired temperature columns\n",
    "        high_drought_df = pd.DataFrame(data_lines, columns=['Drought_AmbientTemp', 'Drought_ObjectTemp'])\n",
    "        print(f\"Successfully extracted {len(high_drought_df)} high drought temperature rows.\")\n",
    "        return high_drought_df\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {filepath} was not found.\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during parsing: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# --- 2. Main Processing Logic ---\n",
    "def process_data_and_combine():\n",
    "    # File paths\n",
    "    soil_moisture_filepath = 'soilmoisture.csv'\n",
    "    rgb_filepath = '30to40.csv'\n",
    "    \n",
    "    # Base name for the output file with sequential naming logic\n",
    "    base_name = 'combined_rgb_temp_data'\n",
    "    extension = '.csv'\n",
    "    output_filepath = base_name + extension\n",
    "    counter = 1\n",
    "    \n",
    "    # Sequential Naming: combined_rgb_temp_data.csv, combined_rgb_temp_data_1.csv, etc.\n",
    "    while os.path.exists(output_filepath):\n",
    "        print(f\"File {output_filepath} already exists. Generating new filename.\")\n",
    "        output_filepath = f\"{base_name}_{counter}{extension}\"\n",
    "        counter += 1\n",
    "\n",
    "    # A. Extract the high drought data (Ambient Temp and Object Temp only)\n",
    "    drought_df = extract_high_drought_data(soil_moisture_filepath)\n",
    "    \n",
    "    if drought_df.empty:\n",
    "        print(\"Aborting combination process due to missing or empty drought data.\")\n",
    "        return\n",
    "\n",
    "    # B. Load the RGB data\n",
    "    print(f\"Loading RGB data from: {rgb_filepath}\")\n",
    "    try:\n",
    "        rgb_df = pd.read_csv(rgb_filepath)\n",
    "        # Clean RGB columns by removing potential extra whitespace from column names\n",
    "        rgb_df.columns = rgb_df.columns.str.strip()\n",
    "        \n",
    "        # Ensure only the R, G, B columns are kept from this file. \n",
    "        # We assume the first file has columns like Index, Row, Col, R, G, B\n",
    "        if all(col in rgb_df.columns for col in ['R', 'G', 'B']):\n",
    "            # Keep R, G, B and drop any index/row/col metadata\n",
    "            rgb_df = rgb_df[['R', 'G', 'B']]\n",
    "        else:\n",
    "            print(\"Warning: R, G, or B columns not found in 30to40.csv. Keeping all columns from RGB file.\")\n",
    "\n",
    "        print(f\"Successfully loaded {len(rgb_df)} RGB rows.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading RGB file: {e}\")\n",
    "        return\n",
    "\n",
    "    # C. Combine the datasets (Cycling the smaller temperature data over the larger RGB data)\n",
    "    num_rgb_rows = len(rgb_df)\n",
    "    \n",
    "    # Repeat the two-column temperature data and trim it to the exact length of the RGB data\n",
    "    num_drought_rows = len(drought_df)\n",
    "    num_repeats = int(np.ceil(num_rgb_rows / num_drought_rows))\n",
    "    repeated_drought_df = pd.concat([drought_df] * num_repeats, ignore_index=True).head(num_rgb_rows)\n",
    "    \n",
    "    # Ensure indices are aligned for concatenation\n",
    "    rgb_df = rgb_df.reset_index(drop=True)\n",
    "    \n",
    "    # Combine the two dataframes side-by-side (column-wise)\n",
    "    combined_df = pd.concat([rgb_df, repeated_drought_df], axis=1)\n",
    "    \n",
    "    print(f\"Data combination complete. Final dataset size: {len(combined_df)} rows.\")\n",
    "\n",
    "    # D. Save the result to the safe output path\n",
    "    combined_df.to_csv(output_filepath, index=False)\n",
    "    print(f\"\\n--- SUCCESS ---\")\n",
    "    print(f\"Clean, combined data saved to: {output_filepath}\")\n",
    "    print(f\"Final columns: {list(combined_df.columns)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_data_and_combine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29db2dca-c19e-4c56-9bea-fa21ba1d2934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CWSI calculation for file: 'combined_rgb_temp_data.csv'\n",
      "Identified Ambient Temperature Column: 'Drought_AmbientTemp'\n",
      "Identified Object Temperature Column: 'Drought_ObjectTemp'\n",
      "\n",
      "CWSI calculation complete. The file 'combined_rgb_temp_data.csv' has been updated.\n",
      "A new 'CWSI' column and an intermediate 'Delta_T' column have been appended.\n",
      "\n",
      "--- Updated File Preview (Original Columns + New Data) ---\n",
      "    R    G   B  Drought_AmbientTemp  Drought_ObjectTemp  Delta_T   CWSI\n",
      "0  80  130  77                26.71               25.37    -1.34  0.986\n",
      "1  84  131  75                26.71               25.41    -1.30  1.000\n",
      "2  87  128  80                26.71               25.37    -1.34  0.986\n",
      "3  93  126  87                26.71               25.41    -1.30  1.000\n",
      "4  93  127  90                26.71               25.37    -1.34  0.986\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Constants for CWSI Calculation ---\n",
    "# Lower Limit (LL) of the temperature difference (Tobj - Tair) for non-stressed conditions\n",
    "LOWER_LIMIT = -2.06\n",
    "\n",
    "# Upper Limit (UL) of the temperature difference (Tobj - Tair) for maximum stress/no-transpiration\n",
    "UPPER_LIMIT = -1.33\n",
    "\n",
    "def calculate_cwsi(filepath):\n",
    "    \"\"\"\n",
    "    Reads a CSV file, calculates the CWSI, adds it as a *new* column \n",
    "    (CWSI), and saves the modified DataFrame back to the original filepath, \n",
    "    preserving all existing columns.\n",
    "\n",
    "    CWSI Formula: CWSI = (dT - LL) / (UL - LL)\n",
    "    Where:\n",
    "        dT is (Object_Temp - Ambient_Temp)\n",
    "        LL is LOWER_LIMIT (-2.06)\n",
    "        UL is UPPER_LIMIT (-1.33)\n",
    "    \"\"\"\n",
    "    print(f\"Starting CWSI calculation for file: '{filepath}'\")\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Error: Input file not found at '{filepath}'\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Load the CSV file into a pandas DataFrame\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Check if the DataFrame has at least 2 columns\n",
    "        if df.shape[1] < 2:\n",
    "            print(\"Error: The CSV must contain at least two columns for temperature data.\")\n",
    "            return\n",
    "\n",
    "        # Identify the columns: second-to-last is Ambient, last is Object\n",
    "        ambient_temp_col_index = df.columns[-2]\n",
    "        object_temp_col_index = df.columns[-1]\n",
    "        \n",
    "        # Print identified columns for user confirmation\n",
    "        print(f\"Identified Ambient Temperature Column: '{ambient_temp_col_index}'\")\n",
    "        print(f\"Identified Object Temperature Column: '{object_temp_col_index}'\")\n",
    "\n",
    "        # Ensure the columns are numeric before calculation\n",
    "        ambient_temps = pd.to_numeric(df[ambient_temp_col_index], errors='coerce')\n",
    "        object_temps = pd.to_numeric(df[object_temp_col_index], errors='coerce')\n",
    "\n",
    "        # 1. Calculate the Temperature Difference (Delta T)\n",
    "        # Delta T = T_Object - T_Ambient\n",
    "        # This is added as an intermediate column for transparency.\n",
    "        df['Delta_T'] = object_temps - ambient_temps\n",
    "        \n",
    "        # 2. Calculate the CWSI\n",
    "        # CWSI = (Delta_T - LL) / (UL - LL)\n",
    "        numerator = df['Delta_T'] - LOWER_LIMIT\n",
    "        denominator = UPPER_LIMIT - LOWER_LIMIT\n",
    "        \n",
    "        # Create the new 'CWSI' column. This does not overwrite any existing data.\n",
    "        df['CWSI'] = numerator / denominator\n",
    "\n",
    "        # Round CWSI values and clip between 0 and 1\n",
    "        df['CWSI'] = df['CWSI'].round(3).clip(lower=0.0, upper=1.0)\n",
    "        \n",
    "        # Save the resulting DataFrame back to the original file path.\n",
    "        # This overwrites the file, but includes all the original data PLUS the new columns.\n",
    "        df.to_csv(filepath, index=False)\n",
    "        \n",
    "        print(f\"\\nCWSI calculation complete. The file '{filepath}' has been updated.\")\n",
    "        print(\"A new 'CWSI' column and an intermediate 'Delta_T' column have been appended.\")\n",
    "        \n",
    "        print(\"\\n--- Updated File Preview (Original Columns + New Data) ---\")\n",
    "        print(df.head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during processing: {e}\")\n",
    "\n",
    "# --- Script Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the input file path (this file will be updated)\n",
    "    input_file = 'combined_rgb_temp_data.csv'\n",
    "    \n",
    "    # Run the calculation\n",
    "    calculate_cwsi(input_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20ab1a2b-3696-4e05-9ad4-904127e939f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: combined_rgb_temp_data.csv\n",
      "\n",
      "--- Z-Score Analysis ---\n",
      "Z-Score Threshold: > 3\n",
      "Total rows in input: 10000\n",
      "Outlier rows found (deleted): 26\n",
      "\n",
      "Filtered data saved successfully to: filtered_rgb_data.csv\n",
      "Rows kept in output file: 9974\n",
      "\n",
      "\n",
      "--- Done ---\n",
      "To run this script, ensure you have pandas and numpy/scipy installed:\n",
      "pip install pandas numpy scipy\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "def filter_rgb_outliers(input_filepath, output_filepath, zscore_threshold=3):\n",
    "    \"\"\"\n",
    "    Reads a CSV file, calculates the Z-scores for R, G, and B columns,\n",
    "    and removes any row where the absolute Z-score of R, G, or B is\n",
    "    greater than the specified threshold (default is 3).\n",
    "\n",
    "    Args:\n",
    "        input_filepath (str): The path to the input CSV file.\n",
    "        output_filepath (str): The path where the filtered data will be saved.\n",
    "        zscore_threshold (float): The absolute Z-score value above which a\n",
    "                                  row is considered an outlier and removed.\n",
    "    \"\"\"\n",
    "    print(f\"Reading data from: {input_filepath}\")\n",
    "\n",
    "    # Check if the input file exists\n",
    "    if not os.path.exists(input_filepath):\n",
    "        print(f\"Error: Input file not found at '{input_filepath}'.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # 1. Read the CSV file\n",
    "        df = pd.read_csv(input_filepath)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Define the columns used for outlier detection\n",
    "    rgb_columns = ['R', 'G', 'B']\n",
    "\n",
    "    # Ensure required columns are present\n",
    "    missing_cols = [col for col in rgb_columns if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Error: CSV is missing required RGB columns: {missing_cols}. Please check column names.\")\n",
    "        return\n",
    "\n",
    "    # 2. Calculate Z-scores for R, G, and B columns\n",
    "    # zscore() calculates the Z-score column-wise by default\n",
    "    z_scores = df[rgb_columns].apply(zscore)\n",
    "\n",
    "    # 3. Create a boolean mask to identify outliers\n",
    "    # We mark a row as an outlier (True) if the absolute Z-score of ANY RGB component is > threshold.\n",
    "    # The .any(axis=1) checks horizontally (across R, G, B) for any True value in the row.\n",
    "    outlier_mask = (np.abs(z_scores) > zscore_threshold).any(axis=1)\n",
    "\n",
    "    # Calculate statistics before filtering\n",
    "    total_rows = len(df)\n",
    "    outlier_rows = outlier_mask.sum()\n",
    "    kept_rows = total_rows - outlier_rows\n",
    "\n",
    "    print(f\"\\n--- Z-Score Analysis ---\")\n",
    "    print(f\"Z-Score Threshold: > {zscore_threshold}\")\n",
    "    print(f\"Total rows in input: {total_rows}\")\n",
    "    print(f\"Outlier rows found (deleted): {outlier_rows}\")\n",
    "\n",
    "    # 4. Delete/Filter the outlier rows\n",
    "    # We select rows where the outlier_mask is False (meaning NOT an outlier)\n",
    "    df_filtered = df[~outlier_mask]\n",
    "\n",
    "    # 5. Save the results to a new file\n",
    "    df_filtered.to_csv(output_filepath, index=False)\n",
    "    print(f\"\\nFiltered data saved successfully to: {output_filepath}\")\n",
    "    print(f\"Rows kept in output file: {kept_rows}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define file paths\n",
    "    input_file = 'combined_rgb_temp_data.csv'\n",
    "    output_file = 'filtered_rgb_data.csv'\n",
    "\n",
    "    # Run the filtering process\n",
    "    filter_rgb_outliers(input_file, output_file)\n",
    "\n",
    "    print(\"\\n\\n--- Done ---\")\n",
    "    print(\"To run this script, ensure you have pandas and numpy/scipy installed:\")\n",
    "    print(\"pip install pandas numpy scipy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f840657a-0c97-4538-8a46-a3932e68c253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
